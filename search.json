[{"path":"https://ohrankwon.github.io/lhsc/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Oh-Ran Kwon. Maintainer.","code":""},{"path":"https://ohrankwon.github.io/lhsc/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Kwon O (2024). lhsc: Leaky Hockey Stick Classifier. R package version 1.0.0, https://ohrankwon.github.io/lhsc/.","code":"@Manual{,   title = {lhsc: Leaky Hockey Stick Classifier},   author = {Oh-Ran Kwon},   year = {2024},   note = {R package version 1.0.0},   url = {https://ohrankwon.github.io/lhsc/}, }"},{"path":"https://ohrankwon.github.io/lhsc/index.html","id":"leaky-hockey-stick-loss-the-first-negatively-divergent-margin-based-loss-function-for-classification","dir":"","previous_headings":"","what":"Leaky Hockey Stick Classifier","title":"Leaky Hockey Stick Classifier","text":"repository provides R package, lhsc, fitting leaky hockey stick classifier, paper: Oh-Ran Kwon Hui Zou (2023) Leaky Hockey Stick Loss: First Negatively Divergent Margin-based Loss Function Classification, Journal Machine Learning Research, 24(239), 1-40. URL: http://jmlr.org/papers/v24/22-1104.html","code":""},{"path":"https://ohrankwon.github.io/lhsc/index.html","id":"installation-of-the-r-package-lhsc","dir":"","previous_headings":"","what":"Installation of the R package lhsc","title":"Leaky Hockey Stick Classifier","text":"may need Fortran compiler (gfortran) system, R package contains Fortran code. proceed, open R prompt type following commands:","code":"library(devtools) devtools::install_github(\"ohrankwon/lhsc\") library(lhsc)"},{"path":"https://ohrankwon.github.io/lhsc/reference/BUPA.html","id":null,"dir":"Reference","previous_headings":"","what":"BUPA's liver disorders data — BUPA","title":"BUPA's liver disorders data — BUPA","text":"BUPA's liver disorders data: 345 male individuals' blood test result liver disorder status.","code":""},{"path":"https://ohrankwon.github.io/lhsc/reference/BUPA.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"BUPA's liver disorders data — BUPA","text":"","code":"data(BUPA)"},{"path":"https://ohrankwon.github.io/lhsc/reference/BUPA.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"BUPA's liver disorders data — BUPA","text":"data set consists 345 observations 6 predictors representing blood test result liver disorder status 345 patients. three predictors mean corpuscular volume (MCV), alkaline phosphotase (ALKPHOS), alamine aminotransferase (SGPT), aspartate aminotransferase (SGOT), gamma-glutamyl transpeptidase (GAMMAGT), number alcoholic beverage drinks per day (DRINKS).","code":""},{"path":"https://ohrankwon.github.io/lhsc/reference/BUPA.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"BUPA's liver disorders data — BUPA","text":"list following elements: X numerical matrix predictors: 345 rows 6 columns; row corresponds patient. y numeric vector length 305 representing liver disorder status.","code":""},{"path":"https://ohrankwon.github.io/lhsc/reference/BUPA.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"BUPA's liver disorders data — BUPA","text":"data set available download UCI machine learning repository. https://archive.ics.uci.edu/ml/datasets/Liver+Disorders","code":""},{"path":"https://ohrankwon.github.io/lhsc/reference/BUPA.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"BUPA's liver disorders data — BUPA","text":"","code":"# load data set data(BUPA)  # the number of samples predictors dim(BUPA$X) #> [1] 345   6  # the number of samples for each class sum(BUPA$y == -1)  #> [1] 145 sum(BUPA$y == 1) #> [1] 200"},{"path":"https://ohrankwon.github.io/lhsc/reference/cv.lhsc.html","id":null,"dir":"Reference","previous_headings":"","what":"cross-validation — cv.lhsc","title":"cross-validation — cv.lhsc","text":"Carry cross-validation lhsc find optimal values tuning parameter lambda.","code":""},{"path":"https://ohrankwon.github.io/lhsc/reference/cv.lhsc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"cross-validation — cv.lhsc","text":"","code":"cv.lhsc(x, y, kern, lambda, nfolds=5, foldid, ...)"},{"path":"https://ohrankwon.github.io/lhsc/reference/cv.lhsc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"cross-validation — cv.lhsc","text":"x matrix predictors, .e., matrix x used lhsc. y vector binary class labels, .e., y used lhsc. y two levels. kern kernel function. lambda user specified lambda candidate sequence cross-validation. nfolds number folds. Default value 5. allowable range 3 sample size. foldid optional vector values 1 nfold, representing fold indices observation. supplied, nfold can missing. ... arguments passed lhsc.","code":""},{"path":"https://ohrankwon.github.io/lhsc/reference/cv.lhsc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"cross-validation — cv.lhsc","text":"function computes mean cross-validation error standard error fitting lhsc every fold excluded alternatively.","code":""},{"path":"https://ohrankwon.github.io/lhsc/reference/cv.lhsc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"cross-validation — cv.lhsc","text":"cv.lhsc object including cross-validation results return. lambda lambda sequence used lhsc. cvm vector length length(lambda): mean cross-validated error. cvsd vector length length(lambda): estimates standard error cvm. cvupper upper curve: cvm + cvsd. cvlower lower curve: cvm - cvsd. lambda.min lambda incurring minimum cross validation error cvm. lambda.1se largest value lambda error within one standard error minimum. cvm.min cross-validation error corresponding lambda.min, .e., least error. cvm.1se cross-validation error corresponding lambda.1se.","code":""},{"path":"https://ohrankwon.github.io/lhsc/reference/cv.lhsc.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"cross-validation — cv.lhsc","text":"Oh-Ran Kwon Hui Zou Maintainer: Oh-ran Kwon  kwon0085@umn.edu","code":""},{"path":"https://ohrankwon.github.io/lhsc/reference/cv.lhsc.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"cross-validation — cv.lhsc","text":"Kwon, O. Zou, H. (2023+) “Leaky Hockey Stick Loss: First Negatively Divergent Margin-based Loss Function Classification\"","code":""},{"path":[]},{"path":"https://ohrankwon.github.io/lhsc/reference/cv.lhsc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"cross-validation — cv.lhsc","text":"","code":"set.seed(1) data(BUPA) BUPA$X = scale(BUPA$X, center=TRUE, scale=TRUE) lambda = 10^(seq(3, -3, length.out=10)) kern = rbfdot(sigma=sigest(BUPA$X)) m.cv = cv.lhsc(BUPA$X, BUPA$y, kern, lambda=lambda, eps=1e-5, maxit=1e5) m.cv$lambda.min #> [1] 0.001"},{"path":"https://ohrankwon.github.io/lhsc/reference/dots.html","id":null,"dir":"Reference","previous_headings":"","what":"Kernel Functions — kernel functions","title":"Kernel Functions — kernel functions","text":"Kernel functions provided R package kernlab. Details can seen reference .   Gaussian RBF kernel \\(k(x,x') = \\exp(-\\sigma \\|x - x'\\|^2)\\)    Polynomial kernel \\(k(x,x') = (scale <x, x'> + offset)^{degree}\\)   Linear kernel \\(k(x,x') = <x, x'>\\)   Laplacian kernel \\(k(x,x') = \\exp(-\\sigma \\|x - x'\\|)\\)    Bessel kernel \\(k(x,x') = (- \\mathrm{Bessel}_{(\\nu+1)}^n \\sigma \\|x - x'\\|^2)\\)    ANOVA RBF kernel \\(k(x,x') = \\sum_{1\\leq i_1 \\ldots < i_D \\leq N}   \\prod_{d=1}^D k(x_{id}, {x'}_{id})\\) k(x, x) Gaussian RBF kernel.    Spline kernel \\( \\prod_{d=1}^D 1 + x_i x_j + x_i x_j \\min(x_i,     x_j)  - \\frac{x_i + x_j}{2} \\min(x_i,x_j)^2 +     \\frac{\\min(x_i,x_j)^3}{3}\\).   parameter sigma used rbfdot can selected sigest().","code":""},{"path":"https://ohrankwon.github.io/lhsc/reference/dots.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Kernel Functions — kernel functions","text":"","code":"rbfdot(sigma = 1) polydot(degree = 1, scale = 1, offset = 1) vanilladot() laplacedot(sigma = 1) besseldot(sigma = 1, order = 1, degree = 1) anovadot(sigma = 1, degree = 1) splinedot() sigest(x)"},{"path":"https://ohrankwon.github.io/lhsc/reference/dots.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Kernel Functions — kernel functions","text":"sigma inverse kernel width used Gaussian,     Laplacian, Bessel, ANOVA kernel. degree degree polynomial, bessel ANOVA     kernel function. positive integer. scale scaling parameter polynomial kernel function. offset offset used polynomial kernel. order order Bessel function used kernel. x design matrix used lhsc sigest called estimate sigma rbfdot().","code":""},{"path":"https://ohrankwon.github.io/lhsc/reference/dots.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Kernel Functions — kernel functions","text":"Return S4 object class kernel can used argument kern fitting lhsc model.","code":""},{"path":"https://ohrankwon.github.io/lhsc/reference/dots.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Kernel Functions — kernel functions","text":"","code":"data(BUPA) # generate a linear kernel kfun = vanilladot()  # generate a Laplacian kernel function with sigma = 1 kfun = laplacedot(sigma=1)  # generate a Gaussian kernel function with sigma estimated by sigest() kfun = rbfdot(sigma=sigest(BUPA$X))  # set kern=kfun when fitting a lhsc object data(BUPA) BUPA$X = scale(BUPA$X, center=TRUE, scale=TRUE) lambda = 10^(seq(-3, 3, length.out=10)) m1 = lhsc(BUPA$X, BUPA$y, kern=kfun,   lambda=lambda, eps=1e-5, maxit=1e5)"},{"path":"https://ohrankwon.github.io/lhsc/reference/lhsc-package.html","id":null,"dir":"Reference","previous_headings":"","what":"Leaky Hockey Stick Classifier — lhsc-package","title":"Leaky Hockey Stick Classifier — lhsc-package","text":"Leaky hockey stick classifier (LHSC) classification algorithm. package provides procedures solving LHSC reproducing kernel Hilbert spaces. algorithm based majorization-minimization (MM) principle compute entire solution path given fine grid regularization parameters.","code":""},{"path":"https://ohrankwon.github.io/lhsc/reference/lhsc-package.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Leaky Hockey Stick Classifier — lhsc-package","text":"Suppose x predictor y binary response. package computes entire solution path grid lambda values. main functions package lhsc include:lhsccv.lhscpredict.lhscplot.lhscplot.cv.lhsc","code":""},{"path":"https://ohrankwon.github.io/lhsc/reference/lhsc-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Leaky Hockey Stick Classifier — lhsc-package","text":"Oh-Ran Kwon Hui Zou Maintainer: Oh-Ran Kwon  kwon0085@umn.edu","code":""},{"path":"https://ohrankwon.github.io/lhsc/reference/lhsc-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Leaky Hockey Stick Classifier — lhsc-package","text":"Kwon, O. Zou, H. (2023+) “Leaky Hockey Stick Loss: First Negatively Divergent Margin-based Loss Function Classification\"","code":""},{"path":"https://ohrankwon.github.io/lhsc/reference/lhsc.html","id":null,"dir":"Reference","previous_headings":"","what":"solve linear LHSC and Kernel LHSC — lhsc","title":"solve linear LHSC and Kernel LHSC — lhsc","text":"Fit LHSC input space reproducing kernel Hilbert space. solution path computed grid values tuning parameter lambda.","code":""},{"path":"https://ohrankwon.github.io/lhsc/reference/lhsc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"solve linear LHSC and Kernel LHSC — lhsc","text":"","code":"lhsc(x, y, kern, lambda, eps=1e-05, maxit=1e+05)"},{"path":"https://ohrankwon.github.io/lhsc/reference/lhsc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"solve linear LHSC and Kernel LHSC — lhsc","text":"x numerical matrix \\(N\\) rows \\(p\\) columns predictors. y vector length \\(N\\) binary responses. element y either -1 1. kern kernel function; see dots. lambda user supplied lambda sequence. eps algorithm stops \\(| \\beta^{old} - \\beta^{new} |\\) less eps. Default value 1e-5. maxit maximum iterations allowed. Default 1e5.","code":""},{"path":"https://ohrankwon.github.io/lhsc/reference/lhsc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"solve linear LHSC and Kernel LHSC — lhsc","text":"leaky hockey stick loss \\(V(u)=1-u\\) \\(u \\le 1\\) \\(-\\log u\\) \\(u > 1\\). value \\(\\lambda\\), .e., lambda, user-specified. linear case (kern inner product N > p), lhsc fits linear LHSC minimizing L2 penalized leaky hockey stick loss function, $$L(\\beta_0,\\beta) := \\frac{1}{N}\\sum_{=1}^N V(y_i(\\beta_0 + X_i'\\beta)) + \\lambda \\beta' \\beta.$$ linear LHSC fitted N < p, kernel LHSC linear kernel actually solved. case, coefficient \\(\\beta\\) can obtained \\(\\beta = X'\\alpha.\\) kernel case, lhsc fits kernel LHSC minimizing $$L(\\alpha_0,\\alpha) := \\frac{1}{n}\\sum_{=1}^n V(y_i(\\alpha_0 + K_i' \\alpha)) + \\lambda \\alpha' K \\alpha,$$ \\(K\\) kernel matrix \\(K_i\\) ith row.","code":""},{"path":"https://ohrankwon.github.io/lhsc/reference/lhsc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"solve linear LHSC and Kernel LHSC — lhsc","text":"object S3 class lhsc. alpha matrix LHSC coefficients lambda value. dimension (p+1)*length(lambda) linear case (N+1)*length(lambda) kernel case. lambda lambda sequence. npass total number FISTA iterations lambda values. jerr Warnings errors; 0 none. info list including parameters loss function, eps, maxit, kern, wt weight vector used. call call produced object.","code":""},{"path":"https://ohrankwon.github.io/lhsc/reference/lhsc.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"solve linear LHSC and Kernel LHSC — lhsc","text":"Oh-ran Kwon Hui Zou Maintainer: Oh-ran Kwon  kwon0085@umn.edu","code":""},{"path":"https://ohrankwon.github.io/lhsc/reference/lhsc.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"solve linear LHSC and Kernel LHSC — lhsc","text":"Kwon, O. Zou, H. (2023+) “Leaky Hockey Stick Loss: First Negatively Divergent Margin-based Loss Function Classification\"","code":""},{"path":[]},{"path":"https://ohrankwon.github.io/lhsc/reference/lhsc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"solve linear LHSC and Kernel LHSC — lhsc","text":"","code":"data(BUPA) # standardize the predictors BUPA$X = scale(BUPA$X, center=TRUE, scale=TRUE)  # a grid of tuning parameters lambda = 10^(seq(3, -3, length.out=10))  # fit a linear LHSC kern = vanilladot() DWD_linear = lhsc(BUPA$X, BUPA$y, kern,   lambda=lambda, eps=1e-5, maxit=1e5)  # fit a kernel LHSC using Gaussian kernel kern = rbfdot(sigma=1) DWD_Gaussian = lhsc(BUPA$X, BUPA$y, kern,   lambda=lambda, eps=1e-5, maxit=1e5)"},{"path":"https://ohrankwon.github.io/lhsc/reference/plot.cv.lhsc.html","id":null,"dir":"Reference","previous_headings":"","what":"plot the cross-validation curve — plot.cv.lhsc","title":"plot the cross-validation curve — plot.cv.lhsc","text":"Plot cross-validation error curves upper lower standard deviations versus log lambda values.","code":""},{"path":"https://ohrankwon.github.io/lhsc/reference/plot.cv.lhsc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"plot the cross-validation curve — plot.cv.lhsc","text":"","code":"# S3 method for class 'cv.lhsc' plot(x, sign.lambda, ...)"},{"path":"https://ohrankwon.github.io/lhsc/reference/plot.cv.lhsc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"plot the cross-validation curve — plot.cv.lhsc","text":"x fitted cv.lhsc object. sign.lambda log(lambda) (default) negative sign.lambda=-1. ... graphical parameters passed plot.","code":""},{"path":"https://ohrankwon.github.io/lhsc/reference/plot.cv.lhsc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"plot the cross-validation curve — plot.cv.lhsc","text":"function plots cross-validation error curves.","code":""},{"path":"https://ohrankwon.github.io/lhsc/reference/plot.cv.lhsc.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"plot the cross-validation curve — plot.cv.lhsc","text":"Oh-Ran Kwon Hui Zou Maintainer: Oh-Ran Kwon  kwon0085@umn.edu","code":""},{"path":[]},{"path":"https://ohrankwon.github.io/lhsc/reference/plot.cv.lhsc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"plot the cross-validation curve — plot.cv.lhsc","text":"","code":"set.seed(1) data(BUPA) BUPA$X = scale(BUPA$X, center=TRUE, scale=TRUE) lambda = 10^(seq(-3, 3, length.out=10)) kern = rbfdot(sigma=sigest(BUPA$X)) m.cv = cv.lhsc(BUPA$X, BUPA$y, kern,   lambda=lambda, eps=1e-5, maxit=1e5) m.cv #> $lambda #>  [1] 1.000000e+03 2.154435e+02 4.641589e+01 1.000000e+01 2.154435e+00 #>  [6] 4.641589e-01 1.000000e-01 2.154435e-02 4.641589e-03 1.000000e-03 #>  #> $cvm #>  [1] 0.4202899 0.4202899 0.4202899 0.4202899 0.4202899 0.4202899 0.4202899 #>  [8] 0.4202899 0.3536232 0.3217391 #>  #> $cvsd #>  [1] 0.02787737 0.02787737 0.02787737 0.02787737 0.02787737 0.02787737 #>  [7] 0.02787737 0.02787737 0.02695808 0.01613845 #>  #> $cvupper #>  [1] 0.4481672 0.4481672 0.4481672 0.4481672 0.4481672 0.4481672 0.4481672 #>  [8] 0.4481672 0.3805813 0.3378776 #>  #> $cvlower #>  [1] 0.3924125 0.3924125 0.3924125 0.3924125 0.3924125 0.3924125 0.3924125 #>  [8] 0.3924125 0.3266651 0.3056007 #>  #> $lambda.min #> [1] 0.001 #>  #> $lambda.1se #> [1] 0.001 #>  #> $cvm.min #> [1] 0.3217391 #>  #> $cvm.1se #> [1] 0.3217391 #>  #> attr(,\"class\") #> [1] \"cv.lhsc\""},{"path":"https://ohrankwon.github.io/lhsc/reference/plot.lhsc.html","id":null,"dir":"Reference","previous_headings":"","what":"plot coefficients — plot.lhsc","title":"plot coefficients — plot.lhsc","text":"Plot solution paths fitted lhsc object.","code":""},{"path":"https://ohrankwon.github.io/lhsc/reference/plot.lhsc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"plot coefficients — plot.lhsc","text":"","code":"# S3 method for class 'lhsc' plot(x, color=FALSE, ...)"},{"path":"https://ohrankwon.github.io/lhsc/reference/plot.lhsc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"plot coefficients — plot.lhsc","text":"x fitted “lhsc\" model. color TRUE, plots curves rainbow colors; otherwise, gray colors (default). ... graphical parameters plot.","code":""},{"path":"https://ohrankwon.github.io/lhsc/reference/plot.lhsc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"plot coefficients — plot.lhsc","text":"Plots solution paths coefficient profile plot.","code":""},{"path":"https://ohrankwon.github.io/lhsc/reference/plot.lhsc.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"plot coefficients — plot.lhsc","text":"Oh-Ran Kwon Hui Zou Maintainer: Oh-Ran Kwon  kwon0085@umn.edu","code":""},{"path":[]},{"path":"https://ohrankwon.github.io/lhsc/reference/plot.lhsc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"plot coefficients — plot.lhsc","text":"","code":"data(BUPA) BUPA$X = scale(BUPA$X, center=TRUE, scale=TRUE) lambda = 10^(seq(-3, 3, length.out=10)) kern = rbfdot(sigma=sigest(BUPA$X)) m1 = lhsc(BUPA$X, BUPA$y, kern,    lambda=lambda, eps=1e-5, maxit=1e5) plot(m1, color=TRUE)"},{"path":"https://ohrankwon.github.io/lhsc/reference/predict.lhsc.html","id":null,"dir":"Reference","previous_headings":"","what":"predict class labels for new observations — predict.lhsc","title":"predict class labels for new observations — predict.lhsc","text":"Predict binary class labels fitted values lhsc object.","code":""},{"path":"https://ohrankwon.github.io/lhsc/reference/predict.lhsc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"predict class labels for new observations — predict.lhsc","text":"","code":"# S3 method for class 'lhsc' predict(object, kern, x, newx, type=c(\"class\", \"link\"), ...)"},{"path":"https://ohrankwon.github.io/lhsc/reference/predict.lhsc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"predict class labels for new observations — predict.lhsc","text":"object fitted lhsc object. kern kernel function used fitting lhsc object. x predictor matrix, .e., x matrix used fitting lhsc object. newx matrix new values x predictions made. note newx must matrix, predict function accept vector formats newx. type \"class\" \"link\"? \"class\" produces predicted binary class labels \"link\" returns fitted values. Default \"class\". ... used. arguments predict.","code":""},{"path":"https://ohrankwon.github.io/lhsc/reference/predict.lhsc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"predict class labels for new observations — predict.lhsc","text":"\"type\" \"class\", function returns predicted class labels. \"type\" \"link\", result \\(\\beta_0 + x_i'\\beta\\) linear case \\(\\beta_0 + K_i'\\alpha\\) kernel case.","code":""},{"path":"https://ohrankwon.github.io/lhsc/reference/predict.lhsc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"predict class labels for new observations — predict.lhsc","text":"Returns either predicted class labels fitted values, depending choice type.","code":""},{"path":"https://ohrankwon.github.io/lhsc/reference/predict.lhsc.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"predict class labels for new observations — predict.lhsc","text":"Oh-Ran Kwon Hui Zou Maintainer: Oh-Ran Kwon  kwon0085@umn.edu","code":""},{"path":[]},{"path":"https://ohrankwon.github.io/lhsc/reference/predict.lhsc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"predict class labels for new observations — predict.lhsc","text":"","code":"data(BUPA) BUPA$X = scale(BUPA$X, center=TRUE, scale=TRUE) lambda = 10^(seq(-3, 3, length.out=10)) kern = rbfdot(sigma=sigest(BUPA$X)) m1 = lhsc(BUPA$X, BUPA$y, kern,   lambda=lambda, eps=1e-5, maxit=1e5) predict(m1, kern, BUPA$X, tail(BUPA$X)) #>      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] #> [1,]    1    1    1    1    1    1    1    1    1     1 #> [2,]    1    1    1    1    1    1    1    1    1    -1 #> [3,]    1    1    1    1    1    1    1    1    1     1 #> [4,]    1    1    1    1    1    1    1    1    1    -1 #> [5,]    1    1    1    1    1    1    1    1    1    -1 #> [6,]    1    1    1    1    1    1    1    1    1    -1"}]
